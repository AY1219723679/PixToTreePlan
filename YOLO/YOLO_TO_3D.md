# Converting YOLO Boxes to 3D Points

This document explains how to convert YOLO bounding box coordinates to 3D points using the depth maps generated by PixToTreePlan.

## Overview

The conversion process involves several steps:
1. Loading YOLO bounding box annotations
2. Converting normalized YOLO coordinates to pixel coordinates
3. Sampling points from within these bounding boxes
4. Using a depth map to add the Z (depth) coordinate to each point
5. Optionally normalizing the coordinates for visualization or further processing

## Key Functions

### From `coord_utils.py`:

```python
def pixel_coords_to_3d(pixel_coords, depth_map, z_scale=1.0, normalize=False):
    """
    Convert pixel coordinates (x, y) to 3D coordinates (x, y, z) using a depth map.
    
    Args:
        pixel_coords (list or np.ndarray): List of (x, y) pixel coordinates
        depth_map (np.ndarray): 2D depth map 
        z_scale (float, optional): Scale factor for the z-values
        normalize (bool, optional): Whether to normalize the coordinates
    
    Returns:
        np.ndarray: 3D coordinates as a numpy array of shape (N, 3)
    """
```

This function takes a list of pixel coordinates and a depth map, returning the corresponding 3D coordinates by using depth values as the Z coordinate.

## Using with YOLO Bounding Boxes

### Step 1: Load YOLO labels

Use the `load_yolo_bboxes` function from `yolo_utils.py`:

```python
from YOLO.yolo_utils import load_yolo_bboxes

# Load bounding boxes and convert to pixel coordinates
bboxes = load_yolo_bboxes('path/to/label.txt', 'path/to/image.jpg')
```

### Step 2: Sample points from bounding boxes

You can either use the center points of the boxes or sample multiple points within each box:

```python
import numpy as np

# Option 1: Use center points of boxes
centers = np.array([[box['x_center'], box['y_center']] for box in bboxes])

# Option 2: Sample multiple points from each box
def sample_points_from_boxes(bboxes, num_points_per_box=100):
    all_points = []
    for bbox in bboxes:
        x1, y1 = bbox['x1'], bbox['y1']
        x2, y2 = bbox['x2'], bbox['y2']
        
        # Sample points within the box
        x_points = np.random.uniform(x1, x2, num_points_per_box)
        y_points = np.random.uniform(y1, y2, num_points_per_box)
        box_points = np.column_stack((x_points, y_points))
        all_points.append(box_points)
    
    return np.vstack(all_points)

sampled_points = sample_points_from_boxes(bboxes, num_points_per_box=50)
```

### Step 3: Load the depth map

```python
from main.img_to_pointcloud.coord_utils import load_depth_map

# Load and preprocess the depth map
depth_map = load_depth_map('path/to/depth_map.png')
```

### Step 4: Convert to 3D coordinates

```python
from main.img_to_pointcloud.coord_utils import pixel_coords_to_3d

# Convert to 3D coordinates
coords_3d = pixel_coords_to_3d(sampled_points, depth_map, z_scale=0.5)

# For normalized coordinates (useful for visualization)
coords_3d_norm = pixel_coords_to_3d(sampled_points, depth_map, z_scale=0.5, normalize=True)
```

### Step 5: Visualize or use the 3D points

```python
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Basic 3D visualization
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Color points by depth
colors = plt.cm.viridis(coords_3d_norm[:, 2])

ax.scatter(
    coords_3d_norm[:, 0], 
    coords_3d_norm[:, 1], 
    coords_3d_norm[:, 2], 
    c=colors, s=5
)

ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z (Depth)')
ax.set_title('3D Points from YOLO Boxes')

plt.savefig('3d_visualization.png')
```

## Tips for Working with Depth Maps

1. **Scaling**: Adjust the `z_scale` parameter to control how prominent depth differences appear
2. **Normalization**: Use `normalize=True` to center coordinates, which is useful for visualization
3. **Filtering**: You can filter points based on depth thresholds to focus on specific ranges
4. **Integration**: These 3D points can be integrated into the main point cloud using Open3D

## Demo Script

See `yolo_to_3d_demo.py` for a complete example that:
- Loads YOLO labels and corresponding images
- Samples points from bounding boxes
- Converts to 3D using depth maps
- Creates visualizations
- Exports the points to PLY format if Open3D is available

Run it with:

```
python yolo_to_3d_demo.py --image path/to/image.jpg --label path/to/label.txt --depth path/to/depth_map.png
```
